{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "attention-encoder-decoder-6a7ab-4896-402e-bdd4-5b10899ad.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMk9E3q9WA/8y0jY+RghRAZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kooose38/visualization-for-attention/blob/master/attention_encoder_decoder_6a7ab_4896_402e_bdd4_5b10899ad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsQh4uoPk17B"
      },
      "source": [
        "# Encoder Decoder による再起型文章生成タスク\n",
        "目的: アテンションを可視化することで文章生成におけるネットワークの説明性を学習します。  \n",
        "環境: python3.7.11 google-colab  \n",
        "パッケージ: [requirements.txt](https://github.com/kooose38/visualization-for-attention/blob/master/requirements.txt)  \n",
        "参照: [https://qiita.com/m__k/items/646044788c5f94eadc8d](https://qiita.com/m__k/items/646044788c5f94eadc8d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOqqOZydi7rZ"
      },
      "source": [
        "### load dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "R0trLdWAjU9a",
        "outputId": "f7da93b8-6f18-459f-d4da-6dddcf2c7160"
      },
      "source": [
        "filename = \"data.txt\"\n",
        "inputs, labels = [], []\n",
        "\n",
        "with open(filename, \"r\") as f:\n",
        "  data_list = f.readlines()\n",
        "  for data in data_list:\n",
        "    data = data[:-1]\n",
        "    inputs.append(data.split(\"_\")[0])\n",
        "    labels.append(\"_\"+data.split(\"_\")[1])\n",
        "\n",
        "import pandas as pd \n",
        "\n",
        "df = pd.DataFrame({\"before\": inputs, \"after\": labels})\n",
        "df.sample(10)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>before</th>\n",
              "      <th>after</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46193</th>\n",
              "      <td>jan 15, 1986</td>\n",
              "      <td>_1986-01-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42691</th>\n",
              "      <td>DEC 20, 1990</td>\n",
              "      <td>_1990-12-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31692</th>\n",
              "      <td>Monday, December 12, 2016</td>\n",
              "      <td>_2016-12-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4927</th>\n",
              "      <td>august 29, 2005</td>\n",
              "      <td>_2005-08-29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24780</th>\n",
              "      <td>FEB 28, 1983</td>\n",
              "      <td>_1983-02-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44525</th>\n",
              "      <td>june 20, 1985</td>\n",
              "      <td>_1985-06-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18554</th>\n",
              "      <td>APRIL 27, 2002</td>\n",
              "      <td>_2002-04-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31363</th>\n",
              "      <td>12/31/06</td>\n",
              "      <td>_2006-12-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49566</th>\n",
              "      <td>mar 2, 1986</td>\n",
              "      <td>_1986-03-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47664</th>\n",
              "      <td>APRIL 19, 2010</td>\n",
              "      <td>_2010-04-19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              before        after\n",
              "46193  jan 15, 1986                   _1986-01-15\n",
              "42691  DEC 20, 1990                   _1990-12-20\n",
              "31692  Monday, December 12, 2016      _2016-12-12\n",
              "4927   august 29, 2005                _2005-08-29\n",
              "24780  FEB 28, 1983                   _1983-02-28\n",
              "44525  june 20, 1985                  _1985-06-20\n",
              "18554  APRIL 27, 2002                 _2002-04-27\n",
              "31363  12/31/06                       _2006-12-31\n",
              "49566  mar 2, 1986                    _1986-03-02\n",
              "47664  APRIL 19, 2010                 _2010-04-19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtHq2IqljU61",
        "outputId": "1308405b-f5d5-442d-e6c6-2d528cdb2743"
      },
      "source": [
        "word2index = {}\n",
        "for inp, lab in zip(inputs, labels):\n",
        "  for i in inp:\n",
        "    if i not in word2index:\n",
        "      word2index[i] = len(word2index)\n",
        "  for t in lab:\n",
        "    if t not in word2index:\n",
        "      word2index[t] = len(word2index)\n",
        "\n",
        "print(word2index)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'s': 0, 'e': 1, 'p': 2, 't': 3, 'm': 4, 'b': 5, 'r': 6, ' ': 7, '2': 8, '7': 9, ',': 10, '1': 11, '9': 12, '4': 13, '_': 14, '-': 15, '0': 16, 'A': 17, 'u': 18, 'g': 19, '3': 20, '8': 21, '/': 22, 'T': 23, 'U': 24, 'E': 25, 'S': 26, 'D': 27, 'Y': 28, 'P': 29, 'M': 30, 'B': 31, 'R': 32, '5': 33, 'J': 34, 'N': 35, '6': 36, 'a': 37, 'i': 38, 'l': 39, 'O': 40, 'c': 41, 'o': 42, 'G': 43, 'F': 44, 'y': 45, 'n': 46, 'C': 47, 'W': 48, 'd': 49, 'I': 50, 'L': 51, 'j': 52, 'H': 53, 'v': 54, 'h': 55, 'V': 56, 'f': 57, 'w': 58}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v7s03w7i7kn"
      },
      "source": [
        "### preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFxqMjyrjV1y"
      },
      "source": [
        "import torch\n",
        "dataset = []\n",
        "\n",
        "for inp, lab in zip(inputs, labels):\n",
        "  data = {}\n",
        "  input_ids = []\n",
        "  labels_ids = []\n",
        "  for i in inp:\n",
        "    idx = word2index[i]\n",
        "    input_ids.append(idx)\n",
        "  for l in lab:\n",
        "    idx = word2index[l]\n",
        "    labels_ids.append(idx)\n",
        "\n",
        "  data[\"input_ids\"] = torch.tensor(input_ids, dtype=torch.long) \n",
        "  data[\"labels\"] = torch.tensor(labels_ids, dtype=torch.long)\n",
        "  dataset.append(data)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwtM1L-YjVxM"
      },
      "source": [
        "n_ = len(dataset)\n",
        "n_train = int(n_*.6)\n",
        "n_val = int(n_*.2)\n",
        "\n",
        "train_ds, val_ds, test_ds = dataset[:n_train], dataset[n_train:n_train+n_val], dataset[n_train+n_val:]\n",
        "\n",
        "from torch.utils.data import DataLoader \n",
        "\n",
        "train = DataLoader(train_ds, batch_size=100, shuffle=True)\n",
        "val = DataLoader(val_ds, batch_size=100, shuffle=True)\n",
        "test = DataLoader(test_ds, batch_size=100, shuffle=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkkvVbjNjVeI",
        "outputId": "1505aa3f-0966-4767-a72d-f5c56d1815a5"
      },
      "source": [
        "for r in train:\n",
        "  print(r[\"input_ids\"].size()) # (batch, encoder_token)\n",
        "  print(r[\"labels\"].size()) # (batch, decoder_token)\n",
        "  print(r[\"input_ids\"])\n",
        "  print(r[\"labels\"])\n",
        "  break"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 29])\n",
            "torch.Size([100, 11])\n",
            "tensor([[48,  1, 49,  ..., 12, 21, 16],\n",
            "        [30, 37, 45,  ...,  7,  7,  7],\n",
            "        [26,  1,  2,  ...,  7,  7,  7],\n",
            "        ...,\n",
            "        [23, 18,  1,  ...,  7,  7,  7],\n",
            "        [34, 37, 46,  ...,  7,  7,  7],\n",
            "        [23, 24, 25,  ...,  7,  7,  7]])\n",
            "tensor([[14, 11, 12,  ..., 15, 11,  9],\n",
            "        [14, 11, 12,  ..., 15,  8, 36],\n",
            "        [14,  8, 16,  ..., 15, 16, 13],\n",
            "        ...,\n",
            "        [14, 11, 12,  ..., 15, 11, 33],\n",
            "        [14, 11, 12,  ..., 15, 16, 20],\n",
            "        [14, 11, 12,  ..., 15, 16, 12]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQPBvrbCi7iM"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrWRKO0CwE-d"
      },
      "source": [
        "##### Encoder layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgJC2JHwjaqG"
      },
      "source": [
        "import torch.nn as nn \n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, intermediate_size=1024):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    \n",
        "    self.embed = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2index[\" \"])\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(embedding_dim, hidden_dim),\n",
        "        nn.Dropout(.1),\n",
        "        nn.LayerNorm(hidden_dim)\n",
        "    )\n",
        "    self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.Linear(hidden_dim, intermediate_size),\n",
        "        nn.Dropout(.1),\n",
        "        nn.LayerNorm(intermediate_size),\n",
        "        nn.Linear(intermediate_size, hidden_dim),\n",
        "        nn.GELU(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    x: encoder-input-ids (batch, encoder-token)\n",
        "\n",
        "    hs: encoder-all-hidden (batch, encoder-token, hidden_dim)\n",
        "    output: encoder-last-token-hidden (batch, hidden_dim) 1 token\n",
        "    '''\n",
        "    x = self.embed(x)\n",
        "    hs, out = self.lstm(x)\n",
        "    out = out[0].view(-1, self.hidden_dim) # 最後の系列トークンベクトル\n",
        "\n",
        "    xx = x[:, -1, :].view(-1, x.size()[2])\n",
        "    xx = self.fc(xx)\n",
        "\n",
        "    out1 = self.norm(xx+out)\n",
        "    out2 = self.fc1(out1)\n",
        "\n",
        "    output = self.norm(out2+out)\n",
        "\n",
        "    return output, hs "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIqF1vCnjaJv",
        "outputId": "8003e937-6d3c-4828-e297-3c5b8acea81e"
      },
      "source": [
        "net = Encoder(100, 20, len(word2index))\n",
        "\n",
        "a = torch.rand(1, 12).long()\n",
        "y, hs = net(a)\n",
        "print(y.size())\n",
        "print(hs.size())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 20])\n",
            "torch.Size([1, 12, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY8Yh7FD0Ihj"
      },
      "source": [
        "#### Decoder layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPtlkep2jaC4"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_dim = hidden_dim \n",
        "\n",
        "    self.embed = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2index[\" \"])\n",
        "\n",
        "    self.i2h = nn.Linear(embedding_dim+hidden_dim, hidden_dim)\n",
        "    self.i2hs = nn.Linear(embedding_dim+hidden_dim, hidden_dim)\n",
        "    self.i2o = nn.Linear(embedding_dim+hidden_dim, hidden_dim)\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    self.o2o = nn.Sequential(\n",
        "        nn.Linear(hidden_dim+hidden_dim, hidden_dim),\n",
        "        nn.Dropout(.1),\n",
        "        nn.LayerNorm(hidden_dim),\n",
        "        nn.Linear(hidden_dim, vocab_size)\n",
        "    )\n",
        "\n",
        "  def forward(self, x, hidden, encoder_hs):\n",
        "    '''\n",
        "    x: (batch, decode-token) decoder inputs data <<only 1 token>>\n",
        "    hidden: (batch, hidden_dim) encoder last hidden \n",
        "    encoder_hs: (batch, encoder-token, hidden_dim) all hidden to encoder tokens \n",
        "\n",
        "    out: (batch, vocab_size) decoder output <<only 1 token>>\n",
        "    next_hidden: (batch, hidden_dim)\n",
        "    attn: (batch, encode-token, decode-token) attention weights \n",
        "    '''\n",
        "    x = self.embed(x).view(-1, self.embedding_dim)\n",
        "    x_h = torch.cat((x, hidden), dim=1)\n",
        "    # (batch, hidden_dim)\n",
        "    next_hidden = self.i2h(x_h)\n",
        "    decoder_hs = self.i2hs(x_h).unsqueeze(1)\n",
        "    out = self.i2o(x_h)\n",
        "    # encoder_hs * decoder_hs -> (batch, encoder_token, decoder_token)\n",
        "    attn = torch.matmul(encoder_hs, decoder_hs.view(-1, self.hidden_dim, 1))\n",
        "    attn = self.softmax(attn)\n",
        "    # attenstion-wetghts * encoder_hs -> (batch, encoder_token, hidden_dim)\n",
        "    encoder_hs_for_attn = encoder_hs*attn \n",
        "    # (batch, hidden_dim) encoder context vector\n",
        "    encoder_hs_for_attn = torch.sum(encoder_hs_for_attn, axis=1).view(-1, encoder_hs_for_attn.size()[2]) \n",
        "    # transform size for target size classification\n",
        "    out = torch.cat((out, encoder_hs_for_attn), dim=1)\n",
        "    out = self.o2o(out)\n",
        "\n",
        "    return out, next_hidden, attn \n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBxsV3BzjWhZ",
        "outputId": "ea3b5b75-0833-420b-f1cb-72c95b288651"
      },
      "source": [
        "net = Decoder(100, 20, len(word2index))\n",
        "\n",
        "a = torch.rand(3, 12).long()\n",
        "h = torch.rand(3, 20)\n",
        "hs = torch.rand(3, 10, 20)\n",
        "\n",
        "attn = torch.zeros(3, 10, 1)\n",
        "\n",
        "for i in range(a.size()[1]):\n",
        "  aa = a[:, i]\n",
        "  y, h, att = net(aa, h, hs)\n",
        "  attn = torch.cat((attn, att), dim=2)\n",
        "\n",
        "print(y.size())\n",
        "print(h.size())\n",
        "print(attn[:, :, 1:].size())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 58])\n",
            "torch.Size([3, 20])\n",
            "torch.Size([3, 10, 12])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC6nKMpyi7fz"
      },
      "source": [
        "### training\n",
        "* 教師強制学習\n",
        "* 教師強制なし学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUV8K4TljXXD"
      },
      "source": [
        "from tqdm import tqdm \n",
        "\n",
        "def trainer(train, val, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, num_epochs, flg=True):\n",
        "  device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "  print(f\"device: {device}\")\n",
        "  encoder.to(device)\n",
        "  decoder.to(device)\n",
        "\n",
        "  best_encoder = None \n",
        "  best_decoder = None \n",
        "  best_val_loss = 100000.0\n",
        "\n",
        "  for e in range(num_epochs):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    train_loss = 0 \n",
        "    n_train = 0 \n",
        "    for data in tqdm(train):\n",
        "      encoder_inputs = data[\"input_ids\"]\n",
        "      decoder_ = data[\"labels\"]\n",
        "\n",
        "      encoder_optimizer.zero_grad()\n",
        "      decoder_optimizer.zero_grad()\n",
        "\n",
        "      hidden, encoder_hs = encoder(encoder_inputs)\n",
        "\n",
        "      decoder_inputs = decoder_[:, :-1]\n",
        "      decoder_labels = decoder_[:, 1:]\n",
        "      loss = 0 \n",
        "\n",
        "      if flg:\n",
        "        for i in range(decoder_inputs.size()[1]):\n",
        "          decoder_input = decoder_inputs[:, i] # decoder inputs に正解ラベルを順に用いる\n",
        "          output, hidden, _ = decoder(decoder_input, hidden, encoder_hs)\n",
        "          decoder_label = decoder_labels[:, i].view(-1)\n",
        "          loss += criterion(output, decoder_label)\n",
        "\n",
        "      else:\n",
        "        for i in range(decoder_inputs.size()[1]):\n",
        "          if i == 0:\n",
        "            decoder_input = decoder_inputs[:, i]\n",
        "          output, hidden, _ = decoder(decoder_input, hidden, encoder_hs)\n",
        "          decoder_label = decoder_labels[:, i].view(-1)\n",
        "          loss += criterion(output, decoder_label)\n",
        "          decoder_input = output.argmax(-1).view(-1, 1) # 予測値を次の decoder inputsにする\n",
        "\n",
        "      loss.backward()\n",
        "      encoder_optimizer.step()\n",
        "      decoder_optimizer.step()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "      n_train += decoder_inputs.size()[0]\n",
        "\n",
        "    print(f\"{e+1}/{num_epochs} | train | loss:{train_loss/n_train:.3f}\")\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    n_val = 0 \n",
        "    loss_val = 0 \n",
        "    acc = 0 \n",
        "    n_val_acc = 0 \n",
        "\n",
        "    for data in tqdm(val):\n",
        "      encoder_inputs = data[\"input_ids\"]\n",
        "      decoder_ = data[\"labels\"]\n",
        "\n",
        "      with torch.no_grad():\n",
        "        hidden, encoder_hs = encoder(encoder_inputs)\n",
        "\n",
        "      decoder_inputs = decoder_[:, :-1]\n",
        "      decoder_labels = decoder_[:, 1:]\n",
        "      loss = 0 \n",
        "      for i in range(decoder_inputs.size()[1]):\n",
        "        if i == 0:\n",
        "          decoder_input = decoder_inputs[:, i]\n",
        "        output, hidden, _ = decoder(decoder_input, hidden, encoder_hs)\n",
        "        decoder_label = decoder_labels[:, i].view(-1)\n",
        "        loss += criterion(output, decoder_label)\n",
        "        decoder_input = output.argmax(-1).view(-1, 1)\n",
        "\n",
        "        pred = output.argmax(-1)\n",
        "        acc += torch.sum(pred == decoder_label).item()\n",
        "        n_val_acc += decoder_label.size()[0]\n",
        "      \n",
        "      loss_val += loss \n",
        "      n_val += decoder_inputs.size()[0]\n",
        "\n",
        "    print(f\"{e+1}/{num_epochs} | val | loss: {loss_val/n_val:.3f} accuracy: {acc/n_val_acc:.3f}\")\n",
        "\n",
        "    if best_val_loss > loss_val:\n",
        "      best_encoder = encoder \n",
        "      best_decoder = decoder \n",
        "      best_val_loss = loss_val \n",
        "\n",
        "  print(f\"best validation loss: {best_val_loss/n_val:.3f}\")\n",
        "\n",
        "  return best_encoder, best_decoder \n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqGUtvi7jXRL",
        "outputId": "060ca050-f420-4353-80c7-fa36ee92a0e8"
      },
      "source": [
        "EMBEDDING_DIM = 200\n",
        "HIDDEN_DIM = 100\n",
        "VOCAB_SIZE = len(word2index)\n",
        "\n",
        "encoder = Encoder(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE)\n",
        "decoder = Decoder(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE)\n",
        "\n",
        "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-2)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "train_encoder, train_decoder = trainer(train, val, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, 5)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [00:33<00:00,  8.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/5 | train | loss:0.022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 27.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/5 | val | loss: 0.001 accuracy: 0.998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [00:39<00:00,  7.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2/5 | train | loss:0.002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 25.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2/5 | val | loss: 0.003 accuracy: 0.995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [00:43<00:00,  6.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/5 | train | loss:0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 25.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/5 | val | loss: 0.007 accuracy: 0.987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [00:45<00:00,  6.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/5 | train | loss:0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 25.33it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4/5 | val | loss: 0.001 accuracy: 0.999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [00:48<00:00,  6.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 | train | loss:0.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 | val | loss: 0.001 accuracy: 0.999\n",
            "best validation loss: 0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8_i7AYki7dP"
      },
      "source": [
        "### evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP-0a9UVjYCR",
        "outputId": "3e596773-f6c2-46ff-b444-3a38075cc2c7"
      },
      "source": [
        "def evaluate(test, encoder, decoder, criterion):\n",
        "  device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "  print(f\"device: {device}\")\n",
        "  \n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  n_test = 0 \n",
        "  test_loss = 0 \n",
        "\n",
        "  n_test_acc = 0 \n",
        "  acc = 0 \n",
        "\n",
        "  predict = []\n",
        "  \n",
        "  for data in tqdm(test):\n",
        "    encoder_inputs = data[\"input_ids\"]\n",
        "    decoder_ = data[\"labels\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      hidden, encoder_hs = encoder(encoder_inputs)\n",
        "\n",
        "    decoder_inputs = decoder_[:, :-1]\n",
        "    decoder_labels = decoder_[:, 1:]\n",
        "    loss = 0\n",
        "\n",
        "    pred_dummy = torch.zeros(decoder_inputs.size()[0], 1, dtype=torch.long, device=device)\n",
        "\n",
        "    for i in range(decoder_inputs.size()[1]):\n",
        "      if i == 0:\n",
        "        decoder_input = decoder_inputs[:, i]\n",
        "\n",
        "      with torch.no_grad():\n",
        "        output, hidden, _ = decoder(decoder_input, hidden, encoder_hs)\n",
        "      decoder_label = decoder_labels[:, i].view(-1)\n",
        "      loss += criterion(output, decoder_label)\n",
        "      pred = output.argmax(-1).view(-1)\n",
        "\n",
        "      acc += torch.sum(pred == decoder_label).item()\n",
        "      n_test_acc += decoder_label.size()[0]\n",
        "      decoder_input = output.argmax(-1).view(-1, 1)\n",
        "\n",
        "      pred_dummy = torch.cat((pred_dummy, pred.view(-1, 1)), dim=1)\n",
        "\n",
        "    predict.append(pred_dummy[:, 1:])\n",
        "\n",
        "    test_loss += loss \n",
        "    n_test += decoder_inputs.size()[0]\n",
        "\n",
        "  print(f\"| test | loss: {test_loss/n_test:.3f} accuracy: {acc/n_test_acc:.3f}\")\n",
        "\n",
        "  return predict \n",
        "\n",
        "  \n",
        "pred = evaluate(val, train_encoder, train_decoder, criterion)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:03<00:00, 25.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| test | loss: 0.001 accuracy: 0.999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZOMIVFhi7aj"
      },
      "source": [
        "### saving model \n",
        "+ onnxruntime\n",
        "+ pth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7m2LrQKjZC2",
        "outputId": "70ea4ed1-b9f4-48a3-c6e5-77317dc827fa"
      },
      "source": [
        "import torch.onnx as onnx \n",
        "\n",
        "a = torch.rand(100, 29).long()\n",
        "onnx.export(train_encoder,\n",
        "            a,\n",
        "            \"encoder_attenstion_plot.onnx\",\n",
        "            output_names=[\"hidden\", \"hidden_hs\"],\n",
        "            input_names=[\"input_ids\"])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_opset9.py:2099: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
            "  \"or define the initial states (h0/c0) as inputs of the model. \")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPIuC_mzjY8M"
      },
      "source": [
        "i = torch.rand(100, 1).long()\n",
        "h = torch.rand(100, 100)\n",
        "hs = torch.rand(100, 29, 100)\n",
        "\n",
        "onnx.export(train_decoder,\n",
        "            (i, h, hs),\n",
        "            \"decoder_attention_plot.onnx\",\n",
        "            output_names=[\"output\", \"hidden\", \"attention\"],\n",
        "            input_names=[\"input_ids\", \"hidden\", \"encoder_hidden_hs\"])\n"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwBSB_JUUv-G"
      },
      "source": [
        "torch.save(train_encoder.state_dict(), \"encoder_attention_plot.pth\")\n",
        "torch.save(train_decoder.state_dict(), \"decoder_attention_plot.pth\")"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnyEztgMjLw7"
      },
      "source": [
        "### visualization \n",
        "+ attention weights \n",
        "+ result for pandas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyPElHS9g3hh"
      },
      "source": [
        "index2word = {v: k for k, v in word2index.items()}\n",
        "\n",
        "row = []\n",
        "\n",
        "for i, data in enumerate(val):\n",
        "  input_ids = data[\"input_ids\"]\n",
        "  labels = data[\"labels\"]\n",
        "  predi = pred[i]\n",
        "\n",
        "  for inp, lab, pre in zip(input_ids, labels, predi):\n",
        "    x = [index2word[xx] for xx in inp.numpy().tolist()]\n",
        "    t = [index2word[tt] for tt in lab.numpy().tolist()[1:]]\n",
        "    y = [index2word[yy] for yy in pre.numpy().tolist()]\n",
        "\n",
        "    x_str = \"\".join(x)\n",
        "    t_str = \"\".join(t)\n",
        "    y_str = \"\".join(y)\n",
        "\n",
        "    judge = 1 if t_str == y_str else 0\n",
        "\n",
        "    row.append([x_str, t_str, y_str, judge])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "J_Yf6g0pi37_",
        "outputId": "3bd063f7-37df-4c23-aaa0-2bc0a729e8c1"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "df = pd.DataFrame(row, columns=[\"inputs\", \"labels\", \"prediction\", \"judge\"])\n",
        "df.sample(10)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>labels</th>\n",
              "      <th>prediction</th>\n",
              "      <th>judge</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>7/12/70</td>\n",
              "      <td>1970-07-12</td>\n",
              "      <td>1970-07-05</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>Sunday, November 2, 2014</td>\n",
              "      <td>2014-11-02</td>\n",
              "      <td>2011-05-14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1225</th>\n",
              "      <td>4/21/88</td>\n",
              "      <td>1988-04-21</td>\n",
              "      <td>1984-09-21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7824</th>\n",
              "      <td>12/6/09</td>\n",
              "      <td>2009-12-06</td>\n",
              "      <td>1984-10-20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3878</th>\n",
              "      <td>Sunday, July 16, 2017</td>\n",
              "      <td>2017-07-16</td>\n",
              "      <td>1992-12-16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9871</th>\n",
              "      <td>Mar 23, 1970</td>\n",
              "      <td>1970-03-23</td>\n",
              "      <td>1993-11-02</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2885</th>\n",
              "      <td>aug 29, 1992</td>\n",
              "      <td>1992-08-29</td>\n",
              "      <td>2006-06-09</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4542</th>\n",
              "      <td>12/17/77</td>\n",
              "      <td>1977-12-17</td>\n",
              "      <td>1995-04-05</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6189</th>\n",
              "      <td>NOV 19, 2008</td>\n",
              "      <td>2008-11-19</td>\n",
              "      <td>1988-05-18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8078</th>\n",
              "      <td>Jan 26, 1991</td>\n",
              "      <td>1991-01-26</td>\n",
              "      <td>2005-09-30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             inputs      labels  prediction  judge\n",
              "427   7/12/70                        1970-07-12  1970-07-05      0\n",
              "418   Sunday, November 2, 2014       2014-11-02  2011-05-14      0\n",
              "1225  4/21/88                        1988-04-21  1984-09-21      0\n",
              "7824  12/6/09                        2009-12-06  1984-10-20      0\n",
              "3878  Sunday, July 16, 2017          2017-07-16  1992-12-16      0\n",
              "9871  Mar 23, 1970                   1970-03-23  1993-11-02      0\n",
              "2885  aug 29, 1992                   1992-08-29  2006-06-09      0\n",
              "4542  12/17/77                       1977-12-17  1995-04-05      0\n",
              "6189  NOV 19, 2008                   2008-11-19  1988-05-18      0\n",
              "8078  Jan 26, 1991                   1991-01-26  2005-09-30      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5kCOQeqMK-MC",
        "outputId": "08417e04-0789-434a-e460-d6485d0319a8"
      },
      "source": [
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_attn(test, train_encoder, train_decoder, num_range=3):\n",
        "\n",
        "  for data in test:\n",
        "    encoder_inputs = data[\"input_ids\"]\n",
        "    decoder_ = data[\"labels\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "      hidden, encoder_hs = train_encoder(encoder_inputs)\n",
        "\n",
        "    decoder_inputs = decoder_[:, :-1]\n",
        "    decoder_labels = decoder_[:, 1:]\n",
        "\n",
        "    attn = torch.zeros(decoder_inputs.size()[0], encoder_inputs.size()[1], 1)\n",
        "    predi = torch.zeros(decoder_inputs.size()[0], 1)\n",
        "\n",
        "    for i in range(decoder_inputs.size()[1]):\n",
        "      if i == 0:\n",
        "        decoder_input = decoder_inputs[:, i]\n",
        "      with torch.no_grad():\n",
        "        output, hidden, att = train_decoder(decoder_input, hidden, encoder_hs)\n",
        "      attn = torch.cat((attn, att), dim=2)\n",
        "      pred = output.argmax(-1).view(-1)\n",
        "      decoder_input = output.argmax(-1).view(-1, 1)\n",
        "      predi = torch.cat((predi, pred.view(-1, 1)), dim=1)\n",
        "\n",
        "    attn = attn[:, :, 1:].numpy()\n",
        "    inputs = encoder_inputs.numpy().tolist()\n",
        "    corr = decoder_[:, 1:].numpy().tolist()\n",
        "\n",
        "    for i in range(num_range):\n",
        "      df = pd.DataFrame(attn[i, :, :].reshape(-1, attn.shape[2]),\n",
        "                        index=[index2word[xx] for xx in inputs[i]],\n",
        "                        columns=[index2word[tt] for tt in corr[i]],\n",
        "                        )\n",
        "      \n",
        "      \n",
        "      plt.figure(figsize=(12, 8))\n",
        "      fig = sns.heatmap(df.T, xticklabels=1, yticklabels=1, square=True, linewidths=3,\n",
        "                  cbar_kws=dict(use_gridspec=False, location=\"top\"))\n",
        "      fig = fig.get_figure()\n",
        "      fig.savefig(f\"attention_plot_{i}.png\")\n",
        "      \n",
        "    break \n",
        "\n",
        "plot_attn(test, train_encoder, train_decoder)\n",
        "    "
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}